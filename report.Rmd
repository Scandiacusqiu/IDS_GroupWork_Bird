---
title: "Project title"
author: "by Team-Name: Naomi Pihlaja, Jiaxi Yan, Yupeng Qiu, J|iayi Chen"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load-lib, include = FALSE}
library(tidyverse)
library(tidymodels)



```


```{r load-data, include=FALSE}
data <- read_csv("data/AVONET3_BirdTree.csv")

```


## Research Question

Can we accurately predict certain characteristics of birds using chosen explanatory variables? If we can, we could predict lifestyle elements of lesser known, lesser investigated and/ or bird species. These predictions could be used in scientific research for wildlife conservation and investigation.


## Data

figshare.com. (n.d.). AVONET: morphological, ecological and geographical data for all birds (Tobias et al 2022 Ecology Letters doi: https://doi.org/10.111/ele.13898). [online] Available at: https://figshare.com/s/b990722d72a26b5bfead. 





## Findings

# Introduction

Bird morphology and ecological traits offer valuable insight into how different species adapt to their environments. The AVONET dataset contains thousands of bird species with measurements of their morphology, habitat, and trophic ecology. This dataset allows us to explore questions regarding correlations of different bird traits, and of potential predictive modelling.

Our analysis investigates two key questions:

1. To what extent can morphological traits explain ecological characteristic such as trophic level or latitude?
2. Which morphological variables show meaningful correlations with each other?

These questions were motivated by our hypothesis generated during group discussions, using logical thinking based on our knowledge of biology and animal adaptations based on lifestyle.

# Data Overview

Avonet birdtree contains summary statistics on specific characteristics of birds. Many are numerical variables (eg. Beak depth), but some are categorical (eg. Trophic level).Over 10,000 observations allows for a big sample size.





- Habitat: Where the bird lives
- Trophic.level: Categorical variable based on the composition of a birds' diet
- Hangwingindex: A measurement of a bird's wing shape that indicates flight efficiency and dispersal ability




- Beak.width: Width of the beak at the anterior edge of the nostrils
- Beak.depth: Depth of the beak at the anterior edge of the nostrils
- Centroid.Latitude: The geometric centre of the species range
- Mass: Body mass of species average
- Wing.length: Length from the carpal joint to the tip of the longest primary on the unflattened wing



# Exploratory Statistics
### 1. Correlation: Beak Width & Beak Depth

\n
We began by exploring correlations between traits we suspected to be related based on our knowlegde of bird biology. After constructing a scatterplot with a linear model, the line of best fit indicated a strong positive correlation between beak width and beak depth.

```{r beak length and depth correlation, echo=FALSE}
#Hypothesis: Bird beak depth increases as beak length increases. Positive correlation.

ggplot(data, aes(x=Beak.Width, y=Beak.Depth, color = Centroid.Latitude))+
         geom_point()+
  geom_smooth(method= "lm")+
  labs(title = "Bird beak width & depth",
       x = "Beak width (mm)", 
       y = "Beak depth (mm)")

```

### 2.Predicting Latitude

\n
We then attempted to predict centroid latitude using these morphological variables (beak width and length). However, our model showed no meaningful visual correlation- the colours were mixed throughout the plane of the graph. This suggests that latitude of bird habitats do not strongly affect their morphological adaptations. The lack of correlation was confirmed by our model, using beak shape to predict latitude:
```{r predicting latitude, echo=FALSE}

# Start modelling
set.seed(2801)
data_split1 <- initial_split(data, 0.8)
data_train1 <- training(data_split1)
data_test1 <- testing(data_split1)


# Construct workflow
data_rec1 <- recipe(Centroid.Latitude ~ Beak.Width + Beak.Depth, data = data) %>% 
  step_naomit(all_predictors()) %>% 
  step_dummy(all_nominal(), -all_outcomes())

data_mod1 <- linear_reg() %>% 
  set_engine("lm")

data_wflow1 <- workflow() %>% 
  add_model(data_mod1) %>% 
  add_recipe(data_rec1)

data_fit1 <- data_wflow1 %>% 
  fit(data = data_train1)
# tidy(data_fit)

data_pred1 <- predict(data_fit1, data_test1) %>% 
  bind_cols(data_test1) %>% 
  print(n = 10)

```

\n
The RMSE of 22.2 suggests an average error of 22.2 when predicting latitude. This is a very high error in the context of latitude, which ranges from -90 to 90. A very low R squared value of 0.002 suggests that the model's predictions is not aligned with the actual data, and that centroid latitude is not explained by beak shape.
```{r predicting latitude split test, echo=FALSE}
# Check model performance
folds1 <- vfold_cv(data_train1, v = 5)
data_fit_rs1 <- data_wflow1 %>% 
  fit_resamples(folds1)
collect_metrics(data_fit_rs1)

```


### 3. Exploring Trophic Level

\n
Our further explorations investigated whether the geographic range size of a species could predict whether it belonged to the trophic category scavenger.

\n
First, we conducted a visual exploration of the range Size of birds at different trophic levels via a jitter map. The graph showed that there are some differences in the distribution range of different trophic groups: the range size of carnivorous species is larger and more scattered, while herbivores and omnivores usually have a more medium-sized and more concentrated distribution range. The range of scavengers is relatively small. Overall, there was a weak correlation between trophic level and range size, but it still showed a basic distribution trend. 

```{r exploring trophic level using geom_jitter,  echo=FALSE}

data <- data %>% 
  mutate(Trophic.Level = as.factor(Trophic.Level))

data_clean <- data %>%
    filter(!is.na(Range.Size),
           !is.na(Trophic.Level))

model_trophic_range <- lm(Range.Size ~ Trophic.Level, data = data_clean)
summary(model_trophic_range)

ggplot(data_clean, aes(x = Trophic.Level, y = Range.Size)) +
    geom_jitter()

```

\n
We then decided to try to use a model to analyse the trophic level variable of scavengers with its relationship with range Size. We re-encoded trophic Level as a binary categorical variable to distinguish scavengers ("yes") from non-scavengers ("no").  


```{r exploring trophic level using modelling, echo=FALSE}
data$Scavenger <- factor(ifelse(data$Trophic.Level == "Scavenger", "yes", "no"),
                       levels = c("no", "yes"))

fit_scav <- logistic_reg() %>% 
  set_engine("glm") %>%
  fit(Scavenger ~ Range.Size, data = data)

data_pred <- data %>%
  mutate(.pred_yes = predict(fit_scav, data, type = "prob")$.pred_yes)

data_pred %>%
  roc_curve(Scavenger, .pred_yes, event_level = "second") %>%
  autoplot()
```

\n
Then, using range size as the only independent variable, we constructed a logistic regression model. The resulting AUC was 0.8027, indicating that there are certain trend differences among species of different range sizes in terms of whether they are scavengers.

```{r exploring trophic level using modelling AUC value, echo=FALSE}
data_pred %>%
  roc_auc(Scavenger, .pred_yes, event_level = "second")

data_pred2 <- data_pred %>%
  mutate(Scavenger_num = if_else(Scavenger == "yes", 1, 0))
```

\n
A possible explanation for the limitations of the model could be the very small sample size of scavengers within the data, which was 20.

```{r size of trophic levels, echo= FALSE}
data %>%
  count(Trophic.Level, name = "sample_size")

```


### 4. Predicting Trophic Niche
\n
As we were unsuccessful in predicting trophic level, we moved onto attempting to predict the variable trophic niche, more specifically, whether a bird is an invertivore. We selected hand wing index as a variable and fitted a logistic regression model:

```{r invertivore ~ handwingindex, echo=FALSE}

# Choose needed data
data_hwi <- data %>% 
  select(Trophic.Niche, `Hand-Wing.Index`) %>% 
  mutate(Invertivore = case_when(Trophic.Niche == "Invertivore" ~ "1", 
                       TRUE ~ "0"))


# Start modelling
set.seed(8888)
data_split1 <- initial_split(data_hwi, 0.8)
data_train1 <- training(data_split1)
data_test1 <- testing(data_split1)


# Construct workflow
data_rec1 <- recipe(Invertivore ~ `Hand-Wing.Index`, data = data_train1) %>% 
  step_naomit(all_predictors()) %>% 
  step_dummy(all_nominal(), -all_outcomes())

data_mod1 <- logistic_reg() %>% 
  set_engine("glm")

data_wflow1 <- workflow() %>% 
  add_model(data_mod1) %>% 
  add_recipe(data_rec1)

data_fit1 <- data_wflow1 %>% 
  fit(data = data_train1)
# tidy(data_fit)

data_pred1 <- predict(data_fit1, data_test1, type = "prob") %>% 
  bind_cols(data_test1) %>% 
  print(n = 10)
```

\n
We then checked the model performance, which revealed a relatively high AUC of 0.73, so it's relatively useful in predicting whether the bird is inventivore or not.

```{r check model performence, echo=FALSE}
cut_off_prob <- 0.45
data_pred1 <- data_pred1 %>% 
  mutate(Invertivore_fac = factor(Invertivore), 
         Invertivore_num = as.numeric(Invertivore), 
         .pred = case_when(.pred_1 > cut_off_prob ~ 1, 
                           TRUE ~ 0))

data_pred1 %>% 
  mutate(
    response = if_else(Invertivore == "1", "Invertivore", "Not Invertivore"), 
    Invertivore_pred = if_else(.pred_1 >= cut_off_prob, "Predicted Invertivore", "Predicted Not Invertivore")
  )  %>% 
  count(response, Invertivore_pred) %>% 
  pivot_wider(names_from = Invertivore_pred, values_from = n)

data_pred1 %>%
  roc_curve(
    truth = Invertivore_fac,
    .pred_1,
    event_level = "second"
  ) %>%
  autoplot()

data_pred1 %>%
  roc_auc(
    truth = Invertivore_fac,
    .pred_1,
    event_level = "second"
  )


folds1 <- vfold_cv(data_train1, v = 5)
data_fit_rs1 <- data_wflow1 %>% 
  fit_resamples(folds1)
collect_metrics(data_fit_rs1)

```

### 5. Improving our prediction on Trophic Niche
\n 
In order to improve the model’s ability to distinguish invertivores from other birds, we added a new variable, ```mass```, to the model. We came to this decision after constructing a ```geom_jitter()``` plot, which visually suggested some correlation between trophic niche and mass:

```{r find mass could be a predictor as well, echo=FALSE}
data %>%
  ggplot(aes(x = log(Mass), y = Trophic.Niche)) +
  geom_jitter()
```

\n
We then fitted a model to our chosen variables:

```{r invertivore ~ handwingindex + Mass, echo=FALSE}
# Choose needed data
data_hwi2 <- data %>% 
  select(Trophic.Niche, `Hand-Wing.Index`, Mass) %>% 
  mutate(Invertivore = case_when(Trophic.Niche == "Invertivore" ~ "1", 
                       TRUE ~ "0"))


# Start modelling
set.seed(8888)
data_split2 <- initial_split(data_hwi2)
data_train2 <- training(data_split2)
data_test2 <- testing(data_split2)


# Construct workflow
data_rec2 <- recipe(Invertivore ~ `Hand-Wing.Index` + Mass, data = data_train2) %>% 
  step_naomit(all_predictors()) %>% 
  step_dummy(all_nominal(), -all_outcomes())

data_mod2 <- logistic_reg() %>% 
  set_engine("glm")

data_wflow2 <- workflow() %>% 
  add_model(data_mod2) %>% 
  add_recipe(data_rec2)

data_fit2 <- data_wflow2 %>% 
  fit(data = data_train2)
# tidy(data_fit)

data_pred2 <- predict(data_fit2, data_test2, type = "prob") %>% 
  bind_cols(data_test2) %>% 
  print(n = 10)
```

\n
We then tested our model's performance:

```{r check model performence for trophic niche, echo=FALSE}
cut_off_prob <- 0.45
data_pred2 <- data_pred2 %>% 
  mutate(Invertivore_fac = factor(Invertivore), 
         Invertivore_num = as.numeric(Invertivore), 
         .pred = case_when(.pred_1 > cut_off_prob ~ 1, 
                           TRUE ~ 0))

data_pred2 %>% 
  mutate(
    response = if_else(Invertivore == "1", "Invertivore", "Not Invertivore"), 
    Invertivore_pred = if_else(.pred_1 >= cut_off_prob, "Predicted Invertivore", "Predicted Not Invertivore")
  )  %>% 
  count(response, Invertivore_pred) %>% 
  pivot_wider(names_from = Invertivore_pred, values_from = n)

data_pred2 %>%
  roc_curve(
    truth = Invertivore_fac,
    .pred_1,
    event_level = "second"
  ) %>%
  autoplot()

data_pred2 %>%
  roc_auc(
    truth = Invertivore_fac,
    .pred_1,
    event_level = "second"
  )


folds1 <- vfold_cv(data_train2, v = 5)
data_fit_rs2 <- data_wflow2 %>% 
  fit_resamples(folds1)
collect_metrics(data_fit_rs1)


TP<-1047
TN<-715
FP<- 586
FN<- 151

Sensitivity <- TP/(TP+FN) 
Sensitivity

Specificity <- TN/(TN+FP)
Specificity
```
\n
 The AUC increased from 0.73 to 0.79, which suggests an improvement on the model's ability to predict whether a bird is an invertivore.
 
# 6. Generalisation Performance (Train–Test Split Evaluation)
\n 
To assess how well our models generalise beyond the training data, we applied a train–test split and evaluated the model on a separate test set that was not used during model fitting. This allows us to check whether the patterns learned in the training process hold up when the model encounters new observations. The test-set metrics therefore provide a more realistic indication of predictive performance. In our results, the training-set AUC values were noticeably higher than the test-set AUC values, and the accuracy on the test set was influenced by class imbalance. The sharp drop in AUC indicates that the models do not generalise well and may overfit the training data, which means their predictive ability is limited when applied to unseen cases.

```{r Train–Test Split (HWI-only)}
data_hwi <- data %>% 
  select(Trophic.Niche, `Hand-Wing.Index`) %>% 
  mutate(Invertivore = ifelse(Trophic.Niche == "Invertivore", 1, 0)) %>% 
  mutate(Invertivore = as.numeric(Invertivore))

set.seed(8888)
hwi_split <- initial_split(data_hwi, prop = 0.7, strata = Invertivore)
hwi_train <- training(hwi_split)
hwi_test  <- testing(hwi_split)

hwi_model <- glm(Invertivore ~ `Hand-Wing.Index`,
                 data = hwi_train,
                 family = binomial)

hwi_test_pred <- hwi_test %>%
  mutate(
    Invertivore = factor(Invertivore),
    .pred       = predict(hwi_model, hwi_test, type = "response"),
    .pred_class = factor(ifelse(.pred > 0.5, "1", "0"))
  )

hwi_auc        <- roc_auc(hwi_test_pred, truth = Invertivore, .pred)
hwi_accuracy   <- accuracy(hwi_test_pred, truth = Invertivore, estimate = .pred_class)
hwi_conf_mat   <- conf_mat(hwi_test_pred, truth = Invertivore, estimate = .pred_class)
hwi_sensitivity <- sens(hwi_test_pred, truth = Invertivore, estimate = .pred_class)
hwi_specificity <- spec(hwi_test_pred, truth = Invertivore, estimate = .pred_class)

hwi_auc
hwi_accuracy
hwi_conf_mat
hwi_sensitivity
hwi_specificity

```

```{r Train–Test Split (HWI + Mass)}
data_hwi2 <- data %>% 
  select(Trophic.Niche, `Hand-Wing.Index`, Mass) %>% 
  mutate(Invertivore = ifelse(Trophic.Niche == "Invertivore", 1, 0)) %>%
  mutate(Invertivore = as.numeric(Invertivore))

set.seed(8888)
hwi_mass_split <- initial_split(data_hwi2, prop = 0.7, strata = Invertivore)
hwi_mass_train <- training(hwi_mass_split)
hwi_mass_test  <- testing(hwi_mass_split)

hwi_mass_model <- glm(Invertivore ~ `Hand-Wing.Index` + Mass,
                      data = hwi_mass_train,
                      family = binomial)

hwi_mass_test_pred <- hwi_mass_test %>%
  mutate(
    Invertivore = factor(Invertivore),
    .pred       = predict(hwi_mass_model, hwi_mass_test, type = "response"),
    .pred_class = factor(ifelse(.pred > 0.5, "1", "0"))
  )

hwi_mass_auc        <- roc_auc(hwi_mass_test_pred, truth = Invertivore, .pred)
hwi_mass_accuracy   <- accuracy(hwi_mass_test_pred, truth = Invertivore, estimate = .pred_class)
hwi_mass_conf_mat   <- conf_mat(hwi_mass_test_pred, truth = Invertivore, estimate = .pred_class)
hwi_mass_sensitivity <- sens(hwi_mass_test_pred, truth = Invertivore, estimate = .pred_class)
hwi_mass_specificity <- spec(hwi_mass_test_pred, truth = Invertivore, estimate = .pred_class)

hwi_mass_auc
hwi_mass_accuracy
hwi_mass_conf_mat
hwi_mass_sensitivity
hwi_mass_specificity

```

# Discussion
\n 
Advantages
\n 
One advantage of our investigation is that it applies a range of statistical and data-science tools rather than relying on a single method. By using exploratory data analysis, several forms of regression, and multiple performance metrics, we were able to evaluate the dataset from different perspectives and understand both its structure and its limitations. The project also allowed us to practise key skills such as transforming variables, handling categorical outcomes, comparing models, and interpreting evaluation measures like AUC, sensitivity, specificity, and confusion matrices. Overall, the analysis demonstrates our ability to think critically about modelling choices, assess whether a method is appropriate, and adjust our approach when initial attempts do not produce meaningful results.

\n 
Limitations
\n 
Our investigation also has several limitations. The early linear regressions showed that morphology had almost no ability to explain variables such as latitude, trophic level, or range size, indicating that these relationships depend on many factors not included in the dataset. Some categories, such as scavengers, had too few observations to support meaningful analysis. In the logistic phase, class imbalance made it difficult for the model to identify invertivores, and the sharp drop in test-set AUC suggests that the model does not generalise well and may overfit the training data. The modelling techniques we used were also fairly simple, and our evaluation relied on a single train–test split, meaning the results may vary depending on the way the data were divided. Finally, although the dataset is publicly available, it is important to report our findings cautiously and avoid overstating the model’s predictive ability, given these limitations.

\n 
Future Work
\n 
For future improvement, we would like to expand the modelling approach by incorporating regression methods that offer more flexibility than the basic techniques used in this investigation. This would allow us to capture patterns that simple linear or logistic models could not address. We would also try to learn and strengthen our evaluation process by applying cross-validation in logistic models, which provides a more reliable assessment of model performance than relying on a single train–test split. In addition, we would consider approaches for handling class imbalance and explore how different classification thresholds affect performance. These steps would allow the analysis to become more robust and better suited for complex datasets.

# Conclusion
\n 
Overall, our investigation showed that the ecological variables we initially explored—latitude, trophic level, and range size—had almost no relationship with the morphological traits in our dataset, as reflected by near-zero R² values and high prediction error in the linear models. When we shifted to a logistic regression framework to predict whether a species is an invertivore, the training-set results improved after adding Mass as a predictor, suggesting that it contributed additional information beyond Hand-Wing Index. However, the test-set AUC values fell sharply, indicating poor generalisation and showing that the available morphological measurements are not sufficient for reliable classification. These findings demonstrate that, although different modelling techniques helped us examine the dataset from multiple angles, the overall predictive ability remained limited, and more informative variables or a richer dataset would be required for stronger modelling outcomes.